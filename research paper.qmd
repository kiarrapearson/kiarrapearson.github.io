---
title: "Research Paper"
author: "Kiarra Pearson"
format:
  html:
    self-contained: true
    code-fold: true
    code-tools: true
---

**Introduction**

Gaining a thorough understanding of social media algorithms is crucial in contemporary society, given the prominent role of social media platforms in shaping public opinion and individual actions. These algorithms wield considerable influence by determining the content displayed on users' feeds, utilizing diverse data sources to curate a personalized feed that includes relevant and captivating content for each user. This idea ultimately means that social media algorithms can influence the information that users consume and how they perceive and maneuver through society. By developing a comprehensive understanding of social media algorithms from both technological and sociological perspectives, we can exert control over the power dynamics that exist between these algorithms and their users. This control can lead to a more transparent and fair digital landscape, fostering a society that is better informed. 

This paper investigates three key research questions: How do social media users perceive, comprehend, and respond to social media algorithms?  2) How do these algorithms function in practical terms? 3) What steps can we take to reshape the power dynamics between algorithms and users? The intricate relationship between social media algorithms and social identity highlights the transformative potential of digital platforms. These algorithms not only shape users' perceptions, preferences, and self-presentation but also impact cultural narratives, amplify marginalized voices, and challenge established power structures. Consequently, they offer opportunities for personal growth, cultural empowerment, and social progress. Social media users perceive, understand, and react to algorithms differently. The user experience depends on their experience, knowledge, and platform interactions. Many users, particularly users of the newer generations, are unaware of the existence and impact of algorithms in shaping their social media experience. I found that many users use algorithms as manipulative tools that prioritize certain content and hide or suppress others, potentially influencing their views and behaviors. 

Social media algorithms have become increasingly powerful in shaping our world, mostly reliant on the digital landscape. 

**How do social media users perceive, understand, and react to social media algorithms?**

\"Algorithms (and the) every day\" by Michele Wilson (2017) discusses how algorithms influence the decisions, experiences, and social interactions of individuals. Wilson highlights algorithms' significant role in shaping the information and content individuals encounter. The article emphasizes how algorithms selectively filter and personalize information, creating filter bubbles and echo chambers. These algorithmic mechanisms can reinforce existing biases, limit exposure to diverse perspectives, and hinder the formation of well-informed opinions (Wilson, 2017). Supporting this perspective, research by Pariser (2011) and Sunstein (2017) has shown that algorithmic systems tend to amplify existing beliefs and preferences, potentially narrowing individuals\' worldviews and inhibiting critical thinking. 

My Account Content Log indicates that my TikTok algorithm is heavily filtered and personalized to my interests, but I disagree with the idea that it narrows my worldview and critical thinking. While I acknowledge that my TikTok algorithm has created an echo chamber by showing content that mainly aligns with my beliefs and preferences, my algorithm reinforces my identity and values as a Black woman and as a student, which supports me in maintaining a healthy sense of self. For instance, seeing consistent content from Black social media influencers, Black leaders, politicians, educators, graduates, etc., are all consistent representations of myself, which promotes a diverse and inclusive online ecosystem without suppressing the viewpoints of others. 

\"Algorithmic Folk Theories and Identity: How TikTok Users Co-Produce Knowledge of Identity and Engage in Algorithmic Resistance\" article discusses the ways algorithms and the identities of users correlate in digital spaces. In their study, Karizat et al. (2021) explore how TikTok users co-produce knowledge of identity and engage in algorithmic resistance on the platform. By employing a mixed-methods approach, including surveys, interviews, and content analysis, the researchers delve into the complex dynamics between algorithmic systems, user experiences, and identity construction. The research highlights the concept of algorithmic resistance, where users intentionally challenge or subvert the algorithm\'s influence on their content and identity. This resistance takes various forms, such as diversifying content consumption, collaborating with others, and deliberately creating content that disrupts algorithmic expectations. By engaging in algorithmic resistance, users exert agency and actively shape their experiences on the platform. The findings of this study contribute to our understanding of the intricate relationship between algorithmic systems and user identity on TikTok. It underscores the active role played by users in co-producing knowledge about identity and navigating the algorithmic affordances of the platform. By shedding light on these processes, the research offers valuable insights into how users negotiate their identities and exercise agency within algorithmic environments.

 Social media algorithms are beyond the consumption of information; they begin to shape the self-perception of individuals and construct social identities. Research by other scholars has highlighted how algorithms meditate identity presentation and influence social dynamics within online platforms. Wilson (2017) discusses how algorithms shape users\' understanding of themselves and others. By analyzing user data and behavior, algorithms contribute to personalized experiences and targeting advertising. Thus, online communities are formed based on shared interests and preferences. However, concerns arise regarding the potential for algorithmic systems to reinforce stereotypes and contribute to self-segregation.

Wilson (2017) emphasized the importance of transparency, accountability, and responsible use of algorithms in order to cultivate an informed society in the digital era. The functioning of algorithms is often obscure, creating difficulties for individuals to discern their inherent biases and workings. This lack of transparency can lead to concerns about autonomy and discrimination. Wilson\'s article reinforces the significance of algorithms in shaping everyday life experiences. His findings highlight the potential consequences of algorithmic systems, including the formation of filter bubbles, the impact on identity construction, and the ethical challenges they present. While algorithms offer benefits such as efficiency and personalization, he calls for critical examination and responsible practice to ensure transparency, fairness, and accountability. Overall, Wilson\'s article provides valuable insight into my ethnographic research on the impact of algorithms on the social identity of individuals in contemporary society. Additionally, Wilson\'s article helps me weigh the pros and cons of whether or not algorithms empower social identity online or if it weakens our understanding of diverse perspectives.

**How do these algorithms actually operate in practice?**

While social media algorithms can introduce biases and ethical dilemmas, I argue that they also possess the capability to enrich social identity by offering individuals a platform to discover increased representation that might be lacking in conventional societal contexts. Given the current era where social media holds considerable influence as a source of news and information, it becomes vital to assess the extent to which users are exposed to a diverse range of ideological content. \"Exposure to ideologically diverse news and opinion on Facebook,\" published in Science, explores the correlation between social media consumption and political polarization. While personalized social media algorithms have been scrutinized and criticized, this article suggests a couple of benefits. 1) personalized algorithms can potentially introduce users to a broader range of information, allowing them to encounter different perspectives and expand their understanding of topics. 2) Personalized algorithms can help tailor content to individual interests and preferences, creating a more personalized and relevant user experience. By analyzing users\' behavior, interactions, and preferences, algorithms can curate content that aligns with their specific interests, potentially enhancing user satisfaction and engagement. The personalized nature of social media algorithms contributes to a more enjoyable user experience by presenting content that aligns with individual interests and preferences. This concept can be likened to Black American students who choose to attend Historically Black Colleges and Universities, seeking a personalized educational experience that reflects their social and racial identity.

Moreover, the discussed article delves into the influence of social media algorithms on user experiences, examining the psychological and emotional dimensions such as satisfaction, engagement, and overall well-being. The researchers inform my understanding of the role of social media algorithms in facilitating social interactions and the formation of social identities. However, on the other hand, \"The Filter Bubble: What the Internet is Hiding from You\" (2011) argues that personalized algorithms enhance information discovery. By analyzing user behavior and interests, algorithms surface content that users will likely find interesting and valuable. This process exposes users to a wider range of topics, perspectives, and sources, expanding their knowledge and understanding deeper discovery. Thus, personalized algorithms are crucial in overcoming information overload and enabling efficient exploration of diverse content. 

A study by Matias et al. (2017) emphasizes the positive impact of personalized social media algorithms on user engagement. By presenting users with content that aligns with their preferences, algorithms create an environment where users feel connected and invested, contributing to a vibrant and active social media ecosystem. 

Another benefit of personalized social media algorithms is their role in targeted advertising and monetization. Research by Dellarocas et al. (2019) suggests that algorithms that understand users\' preferences and behaviors can deliver more relevant and effective advertisements. This targeted approach benefits advertisers and users by presenting them with advertisements that align with their interests and needs. Furthermore, highlights the benefits of personalized social media algorithms in information consumption and user experience. In February, I came across several Makeup advertisements by Revlon and L\'oreal Paris featuring Black celebrities-- rapper Megan Thee Stallion and actress Viola Davis. Black representation is not often seen in mainstream media for big makeup brands like Revlon and L\'oreal, I find it ​​important to see diverse backgrounds, challenging homogeneity and promoting a more inclusive and equitable discourse. Moreover, I found it empowering because it amplifies the women's voices in the Black community and challenges negative stereotypes.

![](https://lh4.googleusercontent.com/YS7xRA6bnr0U5ijSRCWZtZJcHQzLIwuoAHkuhwxU31YJQLlOzT-S_47Yr11p18aWWJKl_zKocuvJh5JQ_QZ4e_FUqFANvXcIAWE9xqwg17-yefF-PqYf83KZ4eKw-PHzyqQ9k6MdREy8HPdNRPVGs5E)![](https://lh3.googleusercontent.com/iF1ZFDF7hiQfatV0oiu310HkiPyKM0f5jN8dNcFNxlexl-keTG38DirDvQ762l7PPXzg2GdMYZv7Rio-GHlE-lKGsIaZNJ0x262XRUU8qbKpigKSOf4Oq_oLWrt49rPUeWImjyufMzLObhkGJb08VIU)

\

**Hypothesis**

The algorithmic personalization of TikTok content reinforces existing social hierarchies and perpetuates echo chambers among users. This hypothesis suggests that TikTok algorithms contribute to the reinforcement of social hierarchies and the creation of echo chambers within the platform. The algorithms are designed to tailor content recommendations based on user preferences and behaviors. However, this personalization may lead to narrowing perspectives and amplifying existing biases and preferences. Users are more likely to be exposed to content that aligns with their beliefs, interests, and identities, reinforcing their own views and limited exposure to diverse perspectives. 

The hypothesis proposes that the algorithmic personalization of TikTok content may result in the formation of echo chambers, where users primarily interact with like-minded individuals and are less exposed to alternative viewpoints. This can further entrench social divisions and reinforce existing social hierarchies based on race, gender, socioeconomic status, and other identity markers. The algorithmic recommendations may prioritize popular or trending content, potentially overshadowing marginalized voices and perpetuating inequalities in representation.

**Methodology**

To investigate this hypothesis, I created a new TikTok account to examine user engagement patterns, content diversity, and the potential impact of algorithmic recommendations on reinforcing social hierarchies and forming echo chambers on a new TikTok account. Data metrics from email addresses and locations are essential components that influence TokTok\'s recommendation algorithms. On the new TikTok account, I created a burner device with a new Apple ID email address. I was based in Washington, D.C., in the Foggy Bottom neighborhood near George Washington University during this research study.

**Findings**

 TikTok primarily introduced me to content from popular social media influencers, including advertisements regarding student life, school, and education. Without engaging with any content (liking, commenting, or reposting) on the new TikTok account or allowing my contacts to find my new account, I found that TikTok may have been using data from the new Apple ID which I used to create the new account. The information associated with my Apple ID is my personal information, such as my name and age. Other important information included device information, usage of other apps, and location data. Much of the content on the burner account pertained to \"Student life\" throughout the study. I believe that TikTok used the data from my Apple ID and university location to recommend content that users with similar data metrics have engaged with. Student life and school-related content are popular and trending on TikTok due to finals, midterms, and graduation season. 

\

The new TikTok account I studied became an echo chamber where I was essentially exposed to content relating to educational institutions, student life, and other academic topics that varied across different education levels. The echo chamber positively represented a sense of community and support among students, providing a platform for sharing experiences, offering advice, and building connections with peers in similar educational contexts. While echo chambers can reinforce biases and limited perspectives, I found that \"student TikTok\" did not include content that aligned with political or social viewpoints. I found the content to be very inclusive of all demographics as they discussed the shared experiences of a student in a learning environment. However, the \"Student TikTok\" echo chamber perpetuated certain realistic narratives and beliefs about students' lifestyles that can also be misleading for immature viewers. The platform\'s algorithm did contribute to the dissemination of false or misleading information regarding misleading academic advice, academic shortcuts, fabricated school experiences, bad behavior, and COVID-19 misinformation, but in a rather comedic way. 

![](https://lh4.googleusercontent.com/hOOWqgDO8xerSiqz06WQePS6EcyAux3UXYBXBkcKQgyZtX90--CTCYycnJv4mmG-XVe38TUKV-5SPRFV4uW7nrEzuWsjNih8cNimk7hDHu68kWWpaEY1JbOC6Z3Vy7JSQYRVV7RvKJlRcfasWxlcyiU)![](https://lh3.googleusercontent.com/YtdX0t-bDAZU5CHNqHwYclWRosYp41c69ABEskaYfwJkVjsv46pjutbtM_nL0hRDzl__-MwLEP4dvsnrqbjD2zT1ybayjXsvMHwPThispN-4XWYJOeRMOr3BvhOZhn02G0YpTFQX10sujd0FHhbjJWQ)![](https://lh4.googleusercontent.com/MCHjySWmtTrJCF88PqiOSc_KKdAKdbU9GYp0Ix_fQ3Ko4W0YOeR3yw8wWD6hPJ-fsnrJkJq3jNl_vF0knC-RAAnK-tbJ0zKgxOlHmSCgwNs9q3S3El0ozwcwGfJS8mFZEvM_TmmAs-xlQocm3gO2ulk)

**Discussion**

\"Amplification and its Discontents: Why Regulating the Reach of Online Content is Hard\" is an article by David Keller that delves into the challenges of regulating online content due to the complex interplay of technological, legal, and ethical factors. Keller discusses the role of algorithms in shaping public discourse and the spread of information. He highlights the tension between the desire to curb the negative consequences of amplification, such as the spread of misinformation or harmful content, and the importance of protecting free speech and promoting a diverse marketplace of ideas. This article informs me of the ongoing content moderation and free speech argument. While I do understand the importance of impeding the spread of content that can be harmful and incite destructive behaviors, I still believe that content producers should still be able to express themselves and their sense of humor freely. 

Throughout the article, Keller emphasizes the issue\'s intricate nature and the trade-offs in regulating the reach of online content. He argues that any regulatory interventions should carefully balance the goals of promoting user safety, mitigating harmful effects, and preserving free expression; additionally, he calls for interdisciplinary collaboration and engagement between various stakeholders, including policymakers, platform operators, researchers, and Civil Society to develop nuanced and practical solutions. In the debate about how TikTok balances the need to moderate harmful content while respecting users\' rights to freedom of expression, I argue that the algorithmic nature of TikTok\'s content distribution can inadvertently reinforce existing biases by amplifying certain voices, and in this case, the voices of students. Social media platforms such as TikTok can use transparency, accountability, and user empowerment to ensure that free expression is upheld while mitigating potential harm.

 The echo chamber positively represents a sense of community and support among students, providing a platform for sharing experiences, offering advice, and building connections with peers in similar educational contexts. While echo chambers can reinforce biases and limited perspectives, I found that \"Student TikTok\" did not include content that aligned with political or social viewpoints. I found the content to be very inclusive of all demographics as they discussed the shared experiences of a student in a learning environment. 

**Conclusion**

Understanding the function of algorithms is crucial in today\'s digital age for several reasons: informed decision-making and societal implications beyond individual user experiences. In summary, understanding the function of algorithms is essential to make informed decisions, protecting privacy, holding platforms accountable, and navigating the complex dynamics of digital platforms. It empowers individuals to actively engage with technology in a meaningful way, mitigate potential risk and promote a more transparent and user-centric digital ecosystem.

While personalized social media algorithms can create filter bubbles and echo chambers where users are isolated from diverse perspectives, it enormously benefits users in various ways. Many users find their TikTok algorithms a safe community with like-minded individuals from underrepresented niches with voices that do not always reach mainstream media or more diverse algorithms. To reshape the dynamic between social media and users, we can encourage developing and implementing an algorithmic design that prioritizes diversity, equity, and inclusion. This involves considering algorithms\' potential biases and impacts on marginalized groups and actively working to mitigate any adverse effects. This approach requires a proactive commitment to addressing biases, promoting fairness, and ongoing monitoring and adaptation as societal norms and understandings evolve.

Social media algorithms can significantly influence individuals\' self-perception and identity construction through the influence of influencers. Social media platforms often provide a space where users showcase the highlights of their lives, emphasizing positive experiences, achievements, and happiness. Algorithms often create echo chambers by showing users content aligning with their beliefs and preferences. This can reinforce identities, values, or biases while limiting exposure to diverse perspectives and alternative viewpoints. Users may become more entrenched in their echo chambers, leading to a narrowing of their worldview and a reinforcement of their existing identity constructs. 

A stronger understanding of social media algorithms can result in a more informed and empowered society. Awareness of personalized content can encourage users to actively seek and engage with content outside of their filter bubbles promoting a balanced perspective. Secondly, with media literacy and further knowledge about social media algorithms, users can recognize when they are being presented with misinformation and evaluate the credibility of the content producer. Lastly, after studying the effects of social media algorithms, students and organizations can advocate and raise awareness of the potential consequences of echo chambers, polarization, and the dissemination of misinformation. 

\
\
\
\
\
\
\
\
\

References

Bakshy, E., Eckles, D., & Messing, S. (2015). Exposure to ideologically diverse news and opinion on Facebook. Science, 348(6239), 1130-1132. doi: 10.1126/science.aaa1160

Felzmann, H., Fosch-Villaronga, E., Lutz, C., & Tamò-Larrieux, A. (2020). Towards transparency by design for artificial intelligence. Science and Engineering Ethics, 26(6), 3333-3361. doi: 10.1007/s11948-020-00276-4

Karizat, N., Delmonaco, D., Eslami, M., & Andalibi, N. (2021). Algorithmic Folk Theories and Identity: How TikTok Users Co-Produce Knowledge of Identity and Engage in Algorithmic Resistance. Proceedings of the ACM on Human-Computer Interaction, 5(CSCW2), Article 305. https://doi.org/10.1145/3476046

Keller, D. (2021). Amplification and its discontents: Why regulating the reach of online content is hard. Journal of Free Speech Law, 1, 227-268. Retrieved from https://www.journaloffreespeechlaw.org/keller.pdf

Klonick, K. (2020). The Facebook Oversight Board: Creating an independent institution to adjudicate online free expression. Yale Law Journal, 129(2418). Retrieved from <https://ssrn.com/abstract=3639234>

Pariser, E. (2011). The Filter Bubble: What the Internet is Hiding from You. The Penguin Press.

Swart, J. (2021). Experiencing algorithms: How young people understand, feel about, and engage with algorithmic news selection on social media. Social Media + Society, 7(2), 20563051211008828. doi: 10.1177/20563051211008828

Tufekci, Z. (2014). Engineering the public: Big data, surveillance and computational politics. First Monday, 19(7). Retrieved from https://firstmonday.org/ojs/index.php/fm/article/view/4901

Wilson, M. (2017). Algorithms (and the) everyday. Information, Communication & Society, 20(1), 137-150. doi: 10.1080/1369118X.2016.1149208
