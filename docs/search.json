[
  {
    "objectID": "research paper.html",
    "href": "research paper.html",
    "title": "Research Paper",
    "section": "",
    "text": "Introduction\nGaining a thorough understanding of social media algorithms is crucial in contemporary society, given the prominent role of social media platforms in shaping public opinion and individual actions. These algorithms wield considerable influence by determining the content displayed on users’ feeds, utilizing diverse data sources to curate a personalized feed that includes relevant and captivating content for each user. This idea ultimately means that social media algorithms can influence the information that users consume and how they perceive and maneuver through society. By developing a comprehensive understanding of social media algorithms from both technological and sociological perspectives, we can exert control over the power dynamics that exist between these algorithms and their users. This control can lead to a more transparent and fair digital landscape, fostering a society that is better informed. \nThis paper investigates three key research questions: How do social media users perceive, comprehend, and respond to social media algorithms?  2) How do these algorithms function in practical terms? 3) What steps can we take to reshape the power dynamics between algorithms and users? The intricate relationship between social media algorithms and social identity highlights the transformative potential of digital platforms. These algorithms not only shape users’ perceptions, preferences, and self-presentation but also impact cultural narratives, amplify marginalized voices, and challenge established power structures. Consequently, they offer opportunities for personal growth, cultural empowerment, and social progress. Social media users perceive, understand, and react to algorithms differently. The user experience depends on their experience, knowledge, and platform interactions. Many users, particularly users of the newer generations, are unaware of the existence and impact of algorithms in shaping their social media experience. I found that many users use algorithms as manipulative tools that prioritize certain content and hide or suppress others, potentially influencing their views and behaviors. \nSocial media algorithms have become increasingly powerful in shaping our world, mostly reliant on the digital landscape. \nHow do social media users perceive, understand, and react to social media algorithms?\n\"Algorithms (and the) every day\" by Michele Wilson (2017) discusses how algorithms influence the decisions, experiences, and social interactions of individuals. Wilson highlights algorithms’ significant role in shaping the information and content individuals encounter. The article emphasizes how algorithms selectively filter and personalize information, creating filter bubbles and echo chambers. These algorithmic mechanisms can reinforce existing biases, limit exposure to diverse perspectives, and hinder the formation of well-informed opinions (Wilson, 2017). Supporting this perspective, research by Pariser (2011) and Sunstein (2017) has shown that algorithmic systems tend to amplify existing beliefs and preferences, potentially narrowing individuals' worldviews and inhibiting critical thinking. \nMy Account Content Log indicates that my TikTok algorithm is heavily filtered and personalized to my interests, but I disagree with the idea that it narrows my worldview and critical thinking. While I acknowledge that my TikTok algorithm has created an echo chamber by showing content that mainly aligns with my beliefs and preferences, my algorithm reinforces my identity and values as a Black woman and as a student, which supports me in maintaining a healthy sense of self. For instance, seeing consistent content from Black social media influencers, Black leaders, politicians, educators, graduates, etc., are all consistent representations of myself, which promotes a diverse and inclusive online ecosystem without suppressing the viewpoints of others. \n\"Algorithmic Folk Theories and Identity: How TikTok Users Co-Produce Knowledge of Identity and Engage in Algorithmic Resistance\" article discusses the ways algorithms and the identities of users correlate in digital spaces. In their study, Karizat et al. (2021) explore how TikTok users co-produce knowledge of identity and engage in algorithmic resistance on the platform. By employing a mixed-methods approach, including surveys, interviews, and content analysis, the researchers delve into the complex dynamics between algorithmic systems, user experiences, and identity construction. The research highlights the concept of algorithmic resistance, where users intentionally challenge or subvert the algorithm's influence on their content and identity. This resistance takes various forms, such as diversifying content consumption, collaborating with others, and deliberately creating content that disrupts algorithmic expectations. By engaging in algorithmic resistance, users exert agency and actively shape their experiences on the platform. The findings of this study contribute to our understanding of the intricate relationship between algorithmic systems and user identity on TikTok. It underscores the active role played by users in co-producing knowledge about identity and navigating the algorithmic affordances of the platform. By shedding light on these processes, the research offers valuable insights into how users negotiate their identities and exercise agency within algorithmic environments.\n Social media algorithms are beyond the consumption of information; they begin to shape the self-perception of individuals and construct social identities. Research by other scholars has highlighted how algorithms meditate identity presentation and influence social dynamics within online platforms. Wilson (2017) discusses how algorithms shape users' understanding of themselves and others. By analyzing user data and behavior, algorithms contribute to personalized experiences and targeting advertising. Thus, online communities are formed based on shared interests and preferences. However, concerns arise regarding the potential for algorithmic systems to reinforce stereotypes and contribute to self-segregation.\nWilson (2017) emphasized the importance of transparency, accountability, and responsible use of algorithms in order to cultivate an informed society in the digital era. The functioning of algorithms is often obscure, creating difficulties for individuals to discern their inherent biases and workings. This lack of transparency can lead to concerns about autonomy and discrimination. Wilson's article reinforces the significance of algorithms in shaping everyday life experiences. His findings highlight the potential consequences of algorithmic systems, including the formation of filter bubbles, the impact on identity construction, and the ethical challenges they present. While algorithms offer benefits such as efficiency and personalization, he calls for critical examination and responsible practice to ensure transparency, fairness, and accountability. Overall, Wilson's article provides valuable insight into my ethnographic research on the impact of algorithms on the social identity of individuals in contemporary society. Additionally, Wilson's article helps me weigh the pros and cons of whether or not algorithms empower social identity online or if it weakens our understanding of diverse perspectives.\nHow do these algorithms actually operate in practice?\nWhile social media algorithms can introduce biases and ethical dilemmas, I argue that they also possess the capability to enrich social identity by offering individuals a platform to discover increased representation that might be lacking in conventional societal contexts. Given the current era where social media holds considerable influence as a source of news and information, it becomes vital to assess the extent to which users are exposed to a diverse range of ideological content. \"Exposure to ideologically diverse news and opinion on Facebook,\" published in Science, explores the correlation between social media consumption and political polarization. While personalized social media algorithms have been scrutinized and criticized, this article suggests a couple of benefits. 1) personalized algorithms can potentially introduce users to a broader range of information, allowing them to encounter different perspectives and expand their understanding of topics. 2) Personalized algorithms can help tailor content to individual interests and preferences, creating a more personalized and relevant user experience. By analyzing users' behavior, interactions, and preferences, algorithms can curate content that aligns with their specific interests, potentially enhancing user satisfaction and engagement. The personalized nature of social media algorithms contributes to a more enjoyable user experience by presenting content that aligns with individual interests and preferences. This concept can be likened to Black American students who choose to attend Historically Black Colleges and Universities, seeking a personalized educational experience that reflects their social and racial identity.\nMoreover, the discussed article delves into the influence of social media algorithms on user experiences, examining the psychological and emotional dimensions such as satisfaction, engagement, and overall well-being. The researchers inform my understanding of the role of social media algorithms in facilitating social interactions and the formation of social identities. However, on the other hand, \"The Filter Bubble: What the Internet is Hiding from You\" (2011) argues that personalized algorithms enhance information discovery. By analyzing user behavior and interests, algorithms surface content that users will likely find interesting and valuable. This process exposes users to a wider range of topics, perspectives, and sources, expanding their knowledge and understanding deeper discovery. Thus, personalized algorithms are crucial in overcoming information overload and enabling efficient exploration of diverse content. \nA study by Matias et al. (2017) emphasizes the positive impact of personalized social media algorithms on user engagement. By presenting users with content that aligns with their preferences, algorithms create an environment where users feel connected and invested, contributing to a vibrant and active social media ecosystem. \nAnother benefit of personalized social media algorithms is their role in targeted advertising and monetization. Research by Dellarocas et al. (2019) suggests that algorithms that understand users' preferences and behaviors can deliver more relevant and effective advertisements. This targeted approach benefits advertisers and users by presenting them with advertisements that align with their interests and needs. Furthermore, highlights the benefits of personalized social media algorithms in information consumption and user experience. In February, I came across several Makeup advertisements by Revlon and L'oreal Paris featuring Black celebrities– rapper Megan Thee Stallion and actress Viola Davis. Black representation is not often seen in mainstream media for big makeup brands like Revlon and L'oreal, I find it ​​important to see diverse backgrounds, challenging homogeneity and promoting a more inclusive and equitable discourse. Moreover, I found it empowering because it amplifies the women’s voices in the Black community and challenges negative stereotypes.\n\n\n\nHypothesis\nThe algorithmic personalization of TikTok content reinforces existing social hierarchies and perpetuates echo chambers among users. This hypothesis suggests that TikTok algorithms contribute to the reinforcement of social hierarchies and the creation of echo chambers within the platform. The algorithms are designed to tailor content recommendations based on user preferences and behaviors. However, this personalization may lead to narrowing perspectives and amplifying existing biases and preferences. Users are more likely to be exposed to content that aligns with their beliefs, interests, and identities, reinforcing their own views and limited exposure to diverse perspectives. \nThe hypothesis proposes that the algorithmic personalization of TikTok content may result in the formation of echo chambers, where users primarily interact with like-minded individuals and are less exposed to alternative viewpoints. This can further entrench social divisions and reinforce existing social hierarchies based on race, gender, socioeconomic status, and other identity markers. The algorithmic recommendations may prioritize popular or trending content, potentially overshadowing marginalized voices and perpetuating inequalities in representation.\nMethodology\nTo investigate this hypothesis, I created a new TikTok account to examine user engagement patterns, content diversity, and the potential impact of algorithmic recommendations on reinforcing social hierarchies and forming echo chambers on a new TikTok account. Data metrics from email addresses and locations are essential components that influence TokTok's recommendation algorithms. On the new TikTok account, I created a burner device with a new Apple ID email address. I was based in Washington, D.C., in the Foggy Bottom neighborhood near George Washington University during this research study.\nFindings\n TikTok primarily introduced me to content from popular social media influencers, including advertisements regarding student life, school, and education. Without engaging with any content (liking, commenting, or reposting) on the new TikTok account or allowing my contacts to find my new account, I found that TikTok may have been using data from the new Apple ID which I used to create the new account. The information associated with my Apple ID is my personal information, such as my name and age. Other important information included device information, usage of other apps, and location data. Much of the content on the burner account pertained to \"Student life\" throughout the study. I believe that TikTok used the data from my Apple ID and university location to recommend content that users with similar data metrics have engaged with. Student life and school-related content are popular and trending on TikTok due to finals, midterms, and graduation season. \n\n\nThe new TikTok account I studied became an echo chamber where I was essentially exposed to content relating to educational institutions, student life, and other academic topics that varied across different education levels. The echo chamber positively represented a sense of community and support among students, providing a platform for sharing experiences, offering advice, and building connections with peers in similar educational contexts. While echo chambers can reinforce biases and limited perspectives, I found that \"student TikTok\" did not include content that aligned with political or social viewpoints. I found the content to be very inclusive of all demographics as they discussed the shared experiences of a student in a learning environment. However, the \"Student TikTok\" echo chamber perpetuated certain realistic narratives and beliefs about students’ lifestyles that can also be misleading for immature viewers. The platform's algorithm did contribute to the dissemination of false or misleading information regarding misleading academic advice, academic shortcuts, fabricated school experiences, bad behavior, and COVID-19 misinformation, but in a rather comedic way. \n\nDiscussion\n\"Amplification and its Discontents: Why Regulating the Reach of Online Content is Hard\" is an article by David Keller that delves into the challenges of regulating online content due to the complex interplay of technological, legal, and ethical factors. Keller discusses the role of algorithms in shaping public discourse and the spread of information. He highlights the tension between the desire to curb the negative consequences of amplification, such as the spread of misinformation or harmful content, and the importance of protecting free speech and promoting a diverse marketplace of ideas. This article informs me of the ongoing content moderation and free speech argument. While I do understand the importance of impeding the spread of content that can be harmful and incite destructive behaviors, I still believe that content producers should still be able to express themselves and their sense of humor freely. \nThroughout the article, Keller emphasizes the issue's intricate nature and the trade-offs in regulating the reach of online content. He argues that any regulatory interventions should carefully balance the goals of promoting user safety, mitigating harmful effects, and preserving free expression; additionally, he calls for interdisciplinary collaboration and engagement between various stakeholders, including policymakers, platform operators, researchers, and Civil Society to develop nuanced and practical solutions. In the debate about how TikTok balances the need to moderate harmful content while respecting users' rights to freedom of expression, I argue that the algorithmic nature of TikTok's content distribution can inadvertently reinforce existing biases by amplifying certain voices, and in this case, the voices of students. Social media platforms such as TikTok can use transparency, accountability, and user empowerment to ensure that free expression is upheld while mitigating potential harm.\n The echo chamber positively represents a sense of community and support among students, providing a platform for sharing experiences, offering advice, and building connections with peers in similar educational contexts. While echo chambers can reinforce biases and limited perspectives, I found that \"Student TikTok\" did not include content that aligned with political or social viewpoints. I found the content to be very inclusive of all demographics as they discussed the shared experiences of a student in a learning environment. \nConclusion\nUnderstanding the function of algorithms is crucial in today's digital age for several reasons: informed decision-making and societal implications beyond individual user experiences. In summary, understanding the function of algorithms is essential to make informed decisions, protecting privacy, holding platforms accountable, and navigating the complex dynamics of digital platforms. It empowers individuals to actively engage with technology in a meaningful way, mitigate potential risk and promote a more transparent and user-centric digital ecosystem.\nWhile personalized social media algorithms can create filter bubbles and echo chambers where users are isolated from diverse perspectives, it enormously benefits users in various ways. Many users find their TikTok algorithms a safe community with like-minded individuals from underrepresented niches with voices that do not always reach mainstream media or more diverse algorithms. To reshape the dynamic between social media and users, we can encourage developing and implementing an algorithmic design that prioritizes diversity, equity, and inclusion. This involves considering algorithms' potential biases and impacts on marginalized groups and actively working to mitigate any adverse effects. This approach requires a proactive commitment to addressing biases, promoting fairness, and ongoing monitoring and adaptation as societal norms and understandings evolve.\nSocial media algorithms can significantly influence individuals' self-perception and identity construction through the influence of influencers. Social media platforms often provide a space where users showcase the highlights of their lives, emphasizing positive experiences, achievements, and happiness. Algorithms often create echo chambers by showing users content aligning with their beliefs and preferences. This can reinforce identities, values, or biases while limiting exposure to diverse perspectives and alternative viewpoints. Users may become more entrenched in their echo chambers, leading to a narrowing of their worldview and a reinforcement of their existing identity constructs. \nA stronger understanding of social media algorithms can result in a more informed and empowered society. Awareness of personalized content can encourage users to actively seek and engage with content outside of their filter bubbles promoting a balanced perspective. Secondly, with media literacy and further knowledge about social media algorithms, users can recognize when they are being presented with misinformation and evaluate the credibility of the content producer. Lastly, after studying the effects of social media algorithms, students and organizations can advocate and raise awareness of the potential consequences of echo chambers, polarization, and the dissemination of misinformation. \n\n\n\n\n\n\n\n\n\n\nReferences\nBakshy, E., Eckles, D., & Messing, S. (2015). Exposure to ideologically diverse news and opinion on Facebook. Science, 348(6239), 1130-1132. doi: 10.1126/science.aaa1160\nFelzmann, H., Fosch-Villaronga, E., Lutz, C., & Tamò-Larrieux, A. (2020). Towards transparency by design for artificial intelligence. Science and Engineering Ethics, 26(6), 3333-3361. doi: 10.1007/s11948-020-00276-4\nKarizat, N., Delmonaco, D., Eslami, M., & Andalibi, N. (2021). Algorithmic Folk Theories and Identity: How TikTok Users Co-Produce Knowledge of Identity and Engage in Algorithmic Resistance. Proceedings of the ACM on Human-Computer Interaction, 5(CSCW2), Article 305. https://doi.org/10.1145/3476046\nKeller, D. (2021). Amplification and its discontents: Why regulating the reach of online content is hard. Journal of Free Speech Law, 1, 227-268. Retrieved from https://www.journaloffreespeechlaw.org/keller.pdf\nKlonick, K. (2020). The Facebook Oversight Board: Creating an independent institution to adjudicate online free expression. Yale Law Journal, 129(2418). Retrieved from https://ssrn.com/abstract=3639234\nPariser, E. (2011). The Filter Bubble: What the Internet is Hiding from You. The Penguin Press.\nSwart, J. (2021). Experiencing algorithms: How young people understand, feel about, and engage with algorithmic news selection on social media. Social Media + Society, 7(2), 20563051211008828. doi: 10.1177/20563051211008828\nTufekci, Z. (2014). Engineering the public: Big data, surveillance and computational politics. First Monday, 19(7). Retrieved from https://firstmonday.org/ojs/index.php/fm/article/view/4901\nWilson, M. (2017). Algorithms (and the) everyday. Information, Communication & Society, 20(1), 137-150. doi: 10.1080/1369118X.2016.1149208"
  },
  {
    "objectID": "Analysis Walkthrough.html",
    "href": "Analysis Walkthrough.html",
    "title": "Analysis Walkthrough",
    "section": "",
    "text": "we’ll start by loading our libraries.\n\n\nCode\n#first we'll load our libraries\n#make sure to install the tidyverse if it's not already installed\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\n\n\n\nCode\nlibrary(lubridate)\n\n\nWe’re going to look at some sample data from Texas on housing prices throughout the state.\nFirst, we will load the data.\n\n\nCode\n# run this line below load the data for this assignment\nimpeach <- read_csv(\"https://docs.google.com/spreadsheets/d/e/2PACX-1vRh8d5JaDqBtByzNw2JZF3idaACobDhhk-p7chJoktA0HawELHFOvjQOqCpzGA4MGONvPlR7GASqW-K/pub?gid=1765341510&single=true&output=csv\")\n\n\nRows: 235 Columns: 32\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (19): for_impeachment, last_name, first_name, middle_name, party, state...\ndbl  (10): date_month, date_year, median_income, median_age, pct_nonwhite, p...\ndate  (3): date_exact, date_approx_month, date_comb\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWe are going to see a data file called “impeach” and see which members support impeachment or not.\n\n\nCode\n# it will load a dataframe called \"impeach,\" containing U.S. House Democrats\n# and whether they supported impeachment along with when they announced such support\n\n\nNow use the R codes we have learned throughout class. Note: You are going to see this symbol “%>%.” This symbol is a pipe operator we use in R. It takes the output of one function and passes it into another function as an argument. This allows us to link a sequence of analysis steps.\n\n\nCode\n# FOR EACH OF THE QUESTIONS BELOW, WRITE YOUR WORKING R CODE TO RETURN THE REQUESTED RESULTS\n# USE COMMENTS (PREFACED BY THE #) TO ACCOMPANY YOUR CODE TO EXPLAIN WHAT YOU'RE DOING \n# FOR EACH STEP\n\n\nFrom the data we are given, we will first find for the members who have favored in impeachment. Therefore, we will first write impeach that is the datasheet we will be using for this whole exercise. After that we will use the filter option and put “no” for impeachment and run it.\n\n\nCode\n# 1) The column \"for_impeachment\" indicates whether the member has publicly called for\n# an impeachment inquiry. Filter to return only the ones where the answer is NO.    \n\nimpeach %>% \n  filter(for_impeachment == \"NO\")\n\n\n# A tibble: 26 × 32\n   for_impeachment last_name  first_name middle_name party state district\n   <chr>           <chr>      <chr>      <chr>       <chr> <chr> <chr>   \n 1 NO              Allred     Colin      <NA>        D     TX    32      \n 2 NO              Brindisi   Anthony    <NA>        D     NY    22      \n 3 NO              Bustos     Cheri      <NA>        D     IL    17      \n 4 NO              Cuellar    Henry      <NA>        D     TX    28      \n 5 NO              Cunningham Joe        <NA>        D     SC    1       \n 6 NO              Davids     Sharice    <NA>        D     KS    3       \n 7 NO              Gabbard    Tulsi      <NA>        D     HI    2       \n 8 NO              Golden     Jared      <NA>        D     ME    2       \n 9 NO              Gonzalez   Vicente    <NA>        D     TX    15      \n10 NO              Horn       Kendra     <NA>        D     OK    5       \n# ℹ 16 more rows\n# ℹ 25 more variables: date_exact <date>, date_approx_month <date>,\n#   date_comb <date>, date_month <dbl>, date_year <dbl>,\n#   margin_flag_2018 <chr>, flip_2018 <chr>, house_dist <chr>,\n#   keyrace_rating <chr>, median_income <dbl>,\n#   median_income_compared_to_national <chr>, median_age <dbl>,\n#   median_age_compared_to_national <chr>, pct_nonwhite <dbl>, …\n\n\nWe do the same thing here with question #1, but we add Republican party that Trump won in 2016 and run it.\n\n\nCode\n# 2) Filter to return only results where a member is both against impeachment, and comes from a \n# district that President Trump won in 2016 (which is noted in the \"p16winningparty\" column)\n\nimpeach %>% \n  filter(for_impeachment == \"NO\") %>% \n  filter(p16winningparty == \"R\")\n\n\n# A tibble: 15 × 32\n   for_impeachment last_name    first_name middle_name party state district\n   <chr>           <chr>        <chr>      <chr>       <chr> <chr> <chr>   \n 1 NO              Brindisi     Anthony    <NA>        D     NY    22      \n 2 NO              Bustos       Cheri      <NA>        D     IL    17      \n 3 NO              Cunningham   Joe        <NA>        D     SC    1       \n 4 NO              Golden       Jared      <NA>        D     ME    2       \n 5 NO              Horn         Kendra     <NA>        D     OK    5       \n 6 NO              Kind         Ron        <NA>        D     WI    3       \n 7 NO              Lamb         Conor      <NA>        D     PA    17      \n 8 NO              Lee          Susie      <NA>        D     NV    3       \n 9 NO              McAdams      Ben        <NA>        D     UT    4       \n10 NO              McBath       Lucy       <NA>        D     GA    6       \n11 NO              O'Halleran   Tom        <NA>        D     AZ    1       \n12 NO              Peterson     Collin     C.          D     MN    7       \n13 NO              Rose         Max        <NA>        D     NY    11      \n14 NO              Torres Small Xochitl    <NA>        D     NM    2       \n15 NO              Van Drew     Jefferson  <NA>        D     NJ    2       \n# ℹ 25 more variables: date_exact <date>, date_approx_month <date>,\n#   date_comb <date>, date_month <dbl>, date_year <dbl>,\n#   margin_flag_2018 <chr>, flip_2018 <chr>, house_dist <chr>,\n#   keyrace_rating <chr>, median_income <dbl>,\n#   median_income_compared_to_national <chr>, median_age <dbl>,\n#   median_age_compared_to_national <chr>, pct_nonwhite <dbl>,\n#   pct_nonwhite_compared_to_national <chr>, pct_bachelors <dbl>, …\n\n\nSame here, but we add an addition to the Republican Mitt Romney carried in 2012.\n\n\nCode\n# 3) Filter for only results where a member is against impeachment, comes from a \n# district that President Trump won in 2016 (which is noted in the \"p16winningparty\" column),\n# and also comes from a district that Mitt Romney won in 2012 (\"p12winningparty\").\n\nimpeach %>% \n  filter(for_impeachment == \"NO\") %>% \n  filter(p16winningparty == \"R\") %>% \n  filter(p12winningparty == \"R\")\n\n\n# A tibble: 9 × 32\n  for_impeachment last_name    first_name middle_name party state district\n  <chr>           <chr>        <chr>      <chr>       <chr> <chr> <chr>   \n1 NO              Brindisi     Anthony    <NA>        D     NY    22      \n2 NO              Cunningham   Joe        <NA>        D     SC    1       \n3 NO              Horn         Kendra     <NA>        D     OK    5       \n4 NO              Lamb         Conor      <NA>        D     PA    17      \n5 NO              McAdams      Ben        <NA>        D     UT    4       \n6 NO              McBath       Lucy       <NA>        D     GA    6       \n7 NO              O'Halleran   Tom        <NA>        D     AZ    1       \n8 NO              Peterson     Collin     C.          D     MN    7       \n9 NO              Torres Small Xochitl    <NA>        D     NM    2       \n# ℹ 25 more variables: date_exact <date>, date_approx_month <date>,\n#   date_comb <date>, date_month <dbl>, date_year <dbl>,\n#   margin_flag_2018 <chr>, flip_2018 <chr>, house_dist <chr>,\n#   keyrace_rating <chr>, median_income <dbl>,\n#   median_income_compared_to_national <chr>, median_age <dbl>,\n#   median_age_compared_to_national <chr>, pct_nonwhite <dbl>,\n#   pct_nonwhite_compared_to_national <chr>, pct_bachelors <dbl>, …\n\n\nFor question #4, we are going to filter for members who are for impeachment but only during the the month of Sept in the year of 2019.\n\n\nCode\n# 4) Filter for only results from September 2019 where a member is a YES for impeachment. \n\nimpeach %>% \n  filter(for_impeachment == \"YES\") %>% \n  filter(date_year == \"2019\") %>% \n  filter(date_month == \"9\")\n\n\n# A tibble: 76 × 32\n   for_impeachment last_name  first_name middle_name party state district\n   <chr>           <chr>      <chr>      <chr>       <chr> <chr> <chr>   \n 1 YES             Axne       Cynthia    <NA>        D     IA    3       \n 2 YES             Bass       Karen      <NA>        D     CA    37      \n 3 YES             Bera       Ami        <NA>        D     CA    7       \n 4 YES             Bishop     Sanford    D.          D     GA    2       \n 5 YES             Cartwright Matt       <NA>        D     PA    8       \n 6 YES             Case       Ed         <NA>        D     HI    1       \n 7 YES             Castor     Kathy      <NA>        D     FL    14      \n 8 YES             Cisneros   Gilbert    <NA>        D     CA    39      \n 9 YES             Clyburn    James      E.          D     SC    6       \n10 YES             Cooper     Jim        <NA>        D     TN    5       \n# ℹ 66 more rows\n# ℹ 25 more variables: date_exact <date>, date_approx_month <date>,\n#   date_comb <date>, date_month <dbl>, date_year <dbl>,\n#   margin_flag_2018 <chr>, flip_2018 <chr>, house_dist <chr>,\n#   keyrace_rating <chr>, median_income <dbl>,\n#   median_income_compared_to_national <chr>, median_age <dbl>,\n#   median_age_compared_to_national <chr>, pct_nonwhite <dbl>, …\n\n\nFor question #5, we will put the same for impeachment and the new one we would add is where Hillary Clinton won more than 70% votes in 2016 underneath the CLinton P percent column on the dataset.\n\n\nCode\n# 5) Filter for only results where a member is a YES for impeachment and is from a district\n# where Clinton won more than 70 percent of the vote in 2016 (found in column \"clinton_percent\")\n\nimpeach %>% \n  filter(for_impeachment == \"YES\") %>% \n  filter(clinton_percent > 70)\n\n\n# A tibble: 55 × 32\n   for_impeachment last_name first_name middle_name party state district\n   <chr>           <chr>     <chr>      <chr>       <chr> <chr> <chr>   \n 1 YES             Barragan  Nanette    <NA>        D     CA    44      \n 2 YES             Bass      Karen      <NA>        D     CA    37      \n 3 YES             Beyer     Donald     <NA>        D     VA    8       \n 4 YES             Boyle     Brendan    <NA>        D     PA    2       \n 5 YES             Brown     Anthony    <NA>        D     MD    4       \n 6 YES             Cardenas  Tony       <NA>        D     CA    29      \n 7 YES             Clarke    Yvette     D.          D     NY    9       \n 8 YES             Clay      William    Lacy        D     MO    1       \n 9 YES             Cohen     Steve      <NA>        D     TN    9       \n10 YES             Cummings  Elijah     E.          D     MD    7       \n# ℹ 45 more rows\n# ℹ 25 more variables: date_exact <date>, date_approx_month <date>,\n#   date_comb <date>, date_month <dbl>, date_year <dbl>,\n#   margin_flag_2018 <chr>, flip_2018 <chr>, house_dist <chr>,\n#   keyrace_rating <chr>, median_income <dbl>,\n#   median_income_compared_to_national <chr>, median_age <dbl>,\n#   median_age_compared_to_national <chr>, pct_nonwhite <dbl>, …\n\n\nFor question #6, we are now going to use the term arrange for it to arrange the data from low to high. Hence, going to arrange for people who have a BA degree or higher.\n\n\nCode\n# 6) Sort the entire dataframe based on the percentage of a district that has a \n# bachelor's degree or higher (\"pct_bachelors\"), from lowest to highest\n\nimpeach %>% \n  arrange(pct_bachelors)\n\n\n# A tibble: 235 × 32\n   for_impeachment last_name     first_name middle_name party state district\n   <chr>           <chr>         <chr>      <chr>       <chr> <chr> <chr>   \n 1 YES             Cox           TJ         <NA>        D     CA    21      \n 2 YES             Roybal-Allard Lucille    <NA>        D     CA    40      \n 3 YES             Garcia        Sylvia     <NA>        D     TX    29      \n 4 YES             Veasey        Marc       <NA>        D     TX    33      \n 5 YES             Costa         Jim        <NA>        D     CA    16      \n 6 YES             Barragan      Nanette    <NA>        D     CA    44      \n 7 YES             Serrano       Jose       E.          D     NY    15      \n 8 YES             Vargas        Juan       <NA>        D     CA    51      \n 9 YES             Gallego       Ruben      <NA>        D     AZ    7       \n10 YES             Tlaib         Rashida    <NA>        D     MI    13      \n# ℹ 225 more rows\n# ℹ 25 more variables: date_exact <date>, date_approx_month <date>,\n#   date_comb <date>, date_month <dbl>, date_year <dbl>,\n#   margin_flag_2018 <chr>, flip_2018 <chr>, house_dist <chr>,\n#   keyrace_rating <chr>, median_income <dbl>,\n#   median_income_compared_to_national <chr>, median_age <dbl>,\n#   median_age_compared_to_national <chr>, pct_nonwhite <dbl>, …\n\n\nFor question #7, arrange is the same as question #6 and the only thing I added along with it was those who are against (No) for impeachment.\n\n\nCode\n# 7) Sort the just those who are NO on impeachment based on the percentage of a district that has a \n# bachelor's degree or higher (\"pct_bachelors\"), from lowest to highest\n\nimpeach %>% \n  filter(for_impeachment == \"NO\") %>% \n  arrange(pct_bachelors)\n\n\n# A tibble: 26 × 32\n   for_impeachment last_name    first_name middle_name party state district\n   <chr>           <chr>        <chr>      <chr>       <chr> <chr> <chr>   \n 1 NO              Cuellar      Henry      <NA>        D     TX    28      \n 2 NO              Bustos       Cheri      <NA>        D     IL    17      \n 3 NO              Wilson       Frederica  <NA>        D     FL    24      \n 4 NO              Gonzalez     Vicente    <NA>        D     TX    15      \n 5 NO              Sewell       Terri      <NA>        D     AL    7       \n 6 NO              Lawson       Al         <NA>        D     FL    5       \n 7 NO              Johnson      Eddie      Bernice     D     TX    30      \n 8 NO              Horsford     Steven     <NA>        D     NV    4       \n 9 NO              Torres Small Xochitl    <NA>        D     NM    2       \n10 NO              Peterson     Collin     C.          D     MN    7       \n# ℹ 16 more rows\n# ℹ 25 more variables: date_exact <date>, date_approx_month <date>,\n#   date_comb <date>, date_month <dbl>, date_year <dbl>,\n#   margin_flag_2018 <chr>, flip_2018 <chr>, house_dist <chr>,\n#   keyrace_rating <chr>, median_income <dbl>,\n#   median_income_compared_to_national <chr>, median_age <dbl>,\n#   median_age_compared_to_national <chr>, pct_nonwhite <dbl>, …\n\n\nFor question #8, the first two steps are exaclty the same from question #7 and the only thing that is added is the BA degrees that were below the national average from the data set.\n\n\nCode\n# 8) Sort the just those who are NO on impeachment based on the percentage of a district that has a \n# bachelor's degree or higher (\"pct_bachelors\"), from lowest to highest.\n# Then filter those records by only those whose bachelor's percentage is below the national average (found\n# in the \"pct_bachelors_compared_to_national\" column).\n\nimpeach %>% \n  filter(for_impeachment == \"NO\") %>% \n  arrange(pct_bachelors) %>% \n  filter(pct_bachelors_compared_to_national == \"BELOW\")\n\n\n# A tibble: 19 × 32\n   for_impeachment last_name    first_name middle_name party state district\n   <chr>           <chr>        <chr>      <chr>       <chr> <chr> <chr>   \n 1 NO              Cuellar      Henry      <NA>        D     TX    28      \n 2 NO              Bustos       Cheri      <NA>        D     IL    17      \n 3 NO              Wilson       Frederica  <NA>        D     FL    24      \n 4 NO              Gonzalez     Vicente    <NA>        D     TX    15      \n 5 NO              Sewell       Terri      <NA>        D     AL    7       \n 6 NO              Lawson       Al         <NA>        D     FL    5       \n 7 NO              Johnson      Eddie      Bernice     D     TX    30      \n 8 NO              Horsford     Steven     <NA>        D     NV    4       \n 9 NO              Torres Small Xochitl    <NA>        D     NM    2       \n10 NO              Peterson     Collin     C.          D     MN    7       \n11 NO              Golden       Jared      <NA>        D     ME    2       \n12 NO              O'Halleran   Tom        <NA>        D     AZ    1       \n13 NO              Brindisi     Anthony    <NA>        D     NY    22      \n14 NO              Kind         Ron        <NA>        D     WI    3       \n15 NO              Van Drew     Jefferson  <NA>        D     NJ    2       \n16 NO              Gabbard      Tulsi      <NA>        D     HI    2       \n17 NO              McAdams      Ben        <NA>        D     UT    4       \n18 NO              Schrader     Kurt       <NA>        D     OR    5       \n19 NO              Horn         Kendra     <NA>        D     OK    5       \n# ℹ 25 more variables: date_exact <date>, date_approx_month <date>,\n#   date_comb <date>, date_month <dbl>, date_year <dbl>,\n#   margin_flag_2018 <chr>, flip_2018 <chr>, house_dist <chr>,\n#   keyrace_rating <chr>, median_income <dbl>,\n#   median_income_compared_to_national <chr>, median_age <dbl>,\n#   median_age_compared_to_national <chr>, pct_nonwhite <dbl>,\n#   pct_nonwhite_compared_to_national <chr>, pct_bachelors <dbl>, …\n\n\nFor question #9, we are back to just filtering. I just filtered the state NJ and filtered those members in NJ who are not for impeachment.\n\n\nCode\n# 9) Filter for only members from New Jersey who are NO on impeachment\n\nimpeach %>% \n  filter(state == \"NJ\", for_impeachment == \"NO\")\n\n\n# A tibble: 1 × 32\n  for_impeachment last_name first_name middle_name party state district\n  <chr>           <chr>     <chr>      <chr>       <chr> <chr> <chr>   \n1 NO              Van Drew  Jefferson  <NA>        D     NJ    2       \n# ℹ 25 more variables: date_exact <date>, date_approx_month <date>,\n#   date_comb <date>, date_month <dbl>, date_year <dbl>,\n#   margin_flag_2018 <chr>, flip_2018 <chr>, house_dist <chr>,\n#   keyrace_rating <chr>, median_income <dbl>,\n#   median_income_compared_to_national <chr>, median_age <dbl>,\n#   median_age_compared_to_national <chr>, pct_nonwhite <dbl>,\n#   pct_nonwhite_compared_to_national <chr>, pct_bachelors <dbl>, …\n\n\nFor question #10, we use filter and arrange together again. We filter people for impeachment but only for the ones for impeachment before 2019. Then, we arranged the highest Clinton voters from those years prior to 2019.\n\n\nCode\n# 10) Filter for those who were YES on impeachment, with a declared date prior to 2019. So only\n# those with dates before 2019.  Then sort those so that the highest Clinton vote percentages are \n# at the top.   \n\nimpeach %>% \n  filter(for_impeachment == \"YES\") %>% \n  filter(date_year < 2019) %>% \n  arrange(clinton_percent)\n\n\n# A tibble: 10 × 32\n   for_impeachment last_name first_name middle_name party state district\n   <chr>           <chr>     <chr>      <chr>       <chr> <chr> <chr>   \n 1 YES             Huffman   Jared      <NA>        D     CA    2       \n 2 YES             Sherman   Brad       <NA>        D     CA    30      \n 3 YES             Moore     Gwen       <NA>        D     WI    4       \n 4 YES             Omar      Ilhan      <NA>        D     MN    5       \n 5 YES             Cohen     Steve      <NA>        D     TN    9       \n 6 YES             Green     Al         <NA>        D     TX    9       \n 7 YES             Fudge     Marcia     L.          D     OH    11      \n 8 YES             Clarke    Yvette     D.          D     NY    9       \n 9 YES             Gomez     Jimmy      <NA>        D     CA    34      \n10 YES             Evans     Dwight     <NA>        D     PA    3       \n# ℹ 25 more variables: date_exact <date>, date_approx_month <date>,\n#   date_comb <date>, date_month <dbl>, date_year <dbl>,\n#   margin_flag_2018 <chr>, flip_2018 <chr>, house_dist <chr>,\n#   keyrace_rating <chr>, median_income <dbl>,\n#   median_income_compared_to_national <chr>, median_age <dbl>,\n#   median_age_compared_to_national <chr>, pct_nonwhite <dbl>,\n#   pct_nonwhite_compared_to_national <chr>, pct_bachelors <dbl>, …\n\n\nQuestion #11 you really had to look at the wording of the question carefully. When it says “holdout” for impeachment, that is just another way of saying who are for (yes) impeachment for filtering. Additionally, you have to filter the national GDP that was below from each respected districts. Lastly, we use a new term called nrow that will tell the number of rows it was in from the data set.\n\n\nCode\n# 11) Answer this question with a single numeric answer, and show the R code you\n# used to reach that answer: How many members in the dataset who are holdouts on impeachment\n# come from districts with a GDP below the national figure?\n# Hint: there's a function called nrow() that tells you how many rows are in a dataframe\n\nimpeach %>% \n  filter(for_impeachment == \"YES\") %>% \n  filter(gdp_above_national == \"BELOW\") %>% \n  nrow()\n\n\n[1] 83"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Kiarra M. Pearson",
    "section": "",
    "text": "Hi, I’m Kiarra and I am a 9th grade English teacher in Chicago, Illinois. I am a results-driven young professional with experience in multi-media communications, digital marketing, and brand management in nonprofit and corporate communications. I am highly regarded for my leadership and service.I have goals of leaving an impact on Black communities through storytelling and sustainable service."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Kiarra M. Pearson",
    "section": "Education",
    "text": "Education\nThe George Washington University, B.A. Journalism and Mass Communications\nNational Louis University, M.A.T in Secondary Education"
  },
  {
    "objectID": "index.html#work-experience",
    "href": "index.html#work-experience",
    "title": "Kiarra M. Pearson",
    "section": "Work Experience",
    "text": "Work Experience\nCommonwealth Edison\nChicago Scholars Foundation\nTeach for America Ignite Fellowship\nUniversity of Chicago Charter Woodlawn"
  },
  {
    "objectID": "index.html#skills",
    "href": "index.html#skills",
    "title": "Kiarra M. Pearson",
    "section": "Skills",
    "text": "Skills\nNews Writing and Reporting\nData Analysis\nAdobe Software\nNewsletter Design\nWeb Development"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Resume",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Portfolio.html",
    "href": "Portfolio.html",
    "title": "Portfolio",
    "section": "",
    "text": "Hi here is a research paper I wrote about how TikTok Algorithms shape social identity.\nIntroduction\nGaining a thorough understanding of social media algorithms is crucial in contemporary society, given the prominent role of social media platforms in shaping public opinion and individual actions. These algorithms wield considerable influence by determining the content displayed on users’ feeds, utilizing diverse data sources to curate a personalized feed that includes relevant and captivating content for each user. This idea ultimately means that social media algorithms can influence the information that users consume and how they perceive and maneuver through society. By developing a comprehensive understanding of social media algorithms from both technological and sociological perspectives, we can exert control over the power dynamics that exist between these algorithms and their users. This control can lead to a more transparent and fair digital landscape, fostering a society that is better informed. \nThis paper investigates three key research questions: How do social media users perceive, comprehend, and respond to social media algorithms?  2) How do these algorithms function in practical terms? 3) What steps can we take to reshape the power dynamics between algorithms and users? The intricate relationship between social media algorithms and social identity highlights the transformative potential of digital platforms. These algorithms not only shape users’ perceptions, preferences, and self-presentation but also impact cultural narratives, amplify marginalized voices, and challenge established power structures. Consequently, they offer opportunities for personal growth, cultural empowerment, and social progress. Social media users perceive, understand, and react to algorithms differently. The user experience depends on their experience, knowledge, and platform interactions. Many users, particularly users of the newer generations, are unaware of the existence and impact of algorithms in shaping their social media experience. I found that many users use algorithms as manipulative tools that prioritize certain content and hide or suppress others, potentially influencing their views and behaviors. \nSocial media algorithms have become increasingly powerful in shaping our world, mostly reliant on the digital landscape. \nHow do social media users perceive, understand, and react to social media algorithms?\n\"Algorithms (and the) every day\" by Michele Wilson (2017) discusses how algorithms influence the decisions, experiences, and social interactions of individuals. Wilson highlights algorithms’ significant role in shaping the information and content individuals encounter. The article emphasizes how algorithms selectively filter and personalize information, creating filter bubbles and echo chambers. These algorithmic mechanisms can reinforce existing biases, limit exposure to diverse perspectives, and hinder the formation of well-informed opinions (Wilson, 2017). Supporting this perspective, research by Pariser (2011) and Sunstein (2017) has shown that algorithmic systems tend to amplify existing beliefs and preferences, potentially narrowing individuals' worldviews and inhibiting critical thinking. \nMy Account Content Log indicates that my TikTok algorithm is heavily filtered and personalized to my interests, but I disagree with the idea that it narrows my worldview and critical thinking. While I acknowledge that my TikTok algorithm has created an echo chamber by showing content that mainly aligns with my beliefs and preferences, my algorithm reinforces my identity and values as a Black woman and as a student, which supports me in maintaining a healthy sense of self. For instance, seeing consistent content from Black social media influencers, Black leaders, politicians, educators, graduates, etc., are all consistent representations of myself, which promotes a diverse and inclusive online ecosystem without suppressing the viewpoints of others. \n\"Algorithmic Folk Theories and Identity: How TikTok Users Co-Produce Knowledge of Identity and Engage in Algorithmic Resistance\" article discusses the ways algorithms and the identities of users correlate in digital spaces. In their study, Karizat et al. (2021) explore how TikTok users co-produce knowledge of identity and engage in algorithmic resistance on the platform. By employing a mixed-methods approach, including surveys, interviews, and content analysis, the researchers delve into the complex dynamics between algorithmic systems, user experiences, and identity construction. The research highlights the concept of algorithmic resistance, where users intentionally challenge or subvert the algorithm's influence on their content and identity. This resistance takes various forms, such as diversifying content consumption, collaborating with others, and deliberately creating content that disrupts algorithmic expectations. By engaging in algorithmic resistance, users exert agency and actively shape their experiences on the platform. The findings of this study contribute to our understanding of the intricate relationship between algorithmic systems and user identity on TikTok. It underscores the active role played by users in co-producing knowledge about identity and navigating the algorithmic affordances of the platform. By shedding light on these processes, the research offers valuable insights into how users negotiate their identities and exercise agency within algorithmic environments.\n Social media algorithms are beyond the consumption of information; they begin to shape the self-perception of individuals and construct social identities. Research by other scholars has highlighted how algorithms meditate identity presentation and influence social dynamics within online platforms. Wilson (2017) discusses how algorithms shape users' understanding of themselves and others. By analyzing user data and behavior, algorithms contribute to personalized experiences and targeting advertising. Thus, online communities are formed based on shared interests and preferences. However, concerns arise regarding the potential for algorithmic systems to reinforce stereotypes and contribute to self-segregation.\nWilson (2017) emphasized the importance of transparency, accountability, and responsible use of algorithms in order to cultivate an informed society in the digital era. The functioning of algorithms is often obscure, creating difficulties for individuals to discern their inherent biases and workings. This lack of transparency can lead to concerns about autonomy and discrimination. Wilson's article reinforces the significance of algorithms in shaping everyday life experiences. His findings highlight the potential consequences of algorithmic systems, including the formation of filter bubbles, the impact on identity construction, and the ethical challenges they present. While algorithms offer benefits such as efficiency and personalization, he calls for critical examination and responsible practice to ensure transparency, fairness, and accountability. Overall, Wilson's article provides valuable insight into my ethnographic research on the impact of algorithms on the social identity of individuals in contemporary society. Additionally, Wilson's article helps me weigh the pros and cons of whether or not algorithms empower social identity online or if it weakens our understanding of diverse perspectives.\nHow do these algorithms actually operate in practice?\nWhile social media algorithms can introduce biases and ethical dilemmas, I argue that they also possess the capability to enrich social identity by offering individuals a platform to discover increased representation that might be lacking in conventional societal contexts. Given the current era where social media holds considerable influence as a source of news and information, it becomes vital to assess the extent to which users are exposed to a diverse range of ideological content. \"Exposure to ideologically diverse news and opinion on Facebook,\" published in Science, explores the correlation between social media consumption and political polarization. While personalized social media algorithms have been scrutinized and criticized, this article suggests a couple of benefits. 1) personalized algorithms can potentially introduce users to a broader range of information, allowing them to encounter different perspectives and expand their understanding of topics. 2) Personalized algorithms can help tailor content to individual interests and preferences, creating a more personalized and relevant user experience. By analyzing users' behavior, interactions, and preferences, algorithms can curate content that aligns with their specific interests, potentially enhancing user satisfaction and engagement. The personalized nature of social media algorithms contributes to a more enjoyable user experience by presenting content that aligns with individual interests and preferences. This concept can be likened to Black American students who choose to attend Historically Black Colleges and Universities, seeking a personalized educational experience that reflects their social and racial identity.\nMoreover, the discussed article delves into the influence of social media algorithms on user experiences, examining the psychological and emotional dimensions such as satisfaction, engagement, and overall well-being. The researchers inform my understanding of the role of social media algorithms in facilitating social interactions and the formation of social identities. However, on the other hand, \"The Filter Bubble: What the Internet is Hiding from You\" (2011) argues that personalized algorithms enhance information discovery. By analyzing user behavior and interests, algorithms surface content that users will likely find interesting and valuable. This process exposes users to a wider range of topics, perspectives, and sources, expanding their knowledge and understanding deeper discovery. Thus, personalized algorithms are crucial in overcoming information overload and enabling efficient exploration of diverse content. \nA study by Matias et al. (2017) emphasizes the positive impact of personalized social media algorithms on user engagement. By presenting users with content that aligns with their preferences, algorithms create an environment where users feel connected and invested, contributing to a vibrant and active social media ecosystem. \nAnother benefit of personalized social media algorithms is their role in targeted advertising and monetization. Research by Dellarocas et al. (2019) suggests that algorithms that understand users' preferences and behaviors can deliver more relevant and effective advertisements. This targeted approach benefits advertisers and users by presenting them with advertisements that align with their interests and needs. Furthermore, highlights the benefits of personalized social media algorithms in information consumption and user experience. In February, I came across several Makeup advertisements by Revlon and L'oreal Paris featuring Black celebrities– rapper Megan Thee Stallion and actress Viola Davis. Black representation is not often seen in mainstream media for big makeup brands like Revlon and L'oreal, I find it ​​important to see diverse backgrounds, challenging homogeneity and promoting a more inclusive and equitable discourse. Moreover, I found it empowering because it amplifies the women’s voices in the Black community and challenges negative stereotypes.\n\nHypothesis\nThe algorithmic personalization of TikTok content reinforces existing social hierarchies and perpetuates echo chambers among users. This hypothesis suggests that TikTok algorithms contribute to the reinforcement of social hierarchies and the creation of echo chambers within the platform. The algorithms are designed to tailor content recommendations based on user preferences and behaviors. However, this personalization may lead to narrowing perspectives and amplifying existing biases and preferences. Users are more likely to be exposed to content that aligns with their beliefs, interests, and identities, reinforcing their own views and limited exposure to diverse perspectives. \nThe hypothesis proposes that the algorithmic personalization of TikTok content may result in the formation of echo chambers, where users primarily interact with like-minded individuals and are less exposed to alternative viewpoints. This can further entrench social divisions and reinforce existing social hierarchies based on race, gender, socioeconomic status, and other identity markers. The algorithmic recommendations may prioritize popular or trending content, potentially overshadowing marginalized voices and perpetuating inequalities in representation.\nMethodology\nTo investigate this hypothesis, I created a new TikTok account to examine user engagement patterns, content diversity, and the potential impact of algorithmic recommendations on reinforcing social hierarchies and forming echo chambers on a new TikTok account. Data metrics from email addresses and locations are essential components that influence TokTok's recommendation algorithms. On the new TikTok account, I created a burner device with a new Apple ID email address. I was based in Washington, D.C., in the Foggy Bottom neighborhood near George Washington University during this research study.\nFindings\n TikTok primarily introduced me to content from popular social media influencers, including advertisements regarding student life, school, and education. Without engaging with any content (liking, commenting, or reposting) on the new TikTok account or allowing my contacts to find my new account, I found that TikTok may have been using data from the new Apple ID which I used to create the new account. The information associated with my Apple ID is my personal information, such as my name and age. Other important information included device information, usage of other apps, and location data. Much of the content on the burner account pertained to \"Student life\" throughout the study. I believe that TikTok used the data from my Apple ID and university location to recommend content that users with similar data metrics have engaged with. Student life and school-related content are popular and trending on TikTok due to finals, midterms, and graduation season. \nThe new TikTok account I studied became an echo chamber where I was essentially exposed to content relating to educational institutions, student life, and other academic topics that varied across different education levels. The echo chamber positively represented a sense of community and support among students, providing a platform for sharing experiences, offering advice, and building connections with peers in similar educational contexts. While echo chambers can reinforce biases and limited perspectives, I found that \"student TikTok\" did not include content that aligned with political or social viewpoints. I found the content to be very inclusive of all demographics as they discussed the shared experiences of a student in a learning environment. However, the \"Student TikTok\" echo chamber perpetuated certain realistic narratives and beliefs about students’ lifestyles that can also be misleading for immature viewers. The platform's algorithm did contribute to the dissemination of false or misleading information regarding misleading academic advice, academic shortcuts, fabricated school experiences, bad behavior, and COVID-19 misinformation, but in a rather comedic way. \n\nDiscussion\n\"Amplification and its Discontents: Why Regulating the Reach of Online Content is Hard\" is an article by David Keller that delves into the challenges of regulating online content due to the complex interplay of technological, legal, and ethical factors. Keller discusses the role of algorithms in shaping public discourse and the spread of information. He highlights the tension between the desire to curb the negative consequences of amplification, such as the spread of misinformation or harmful content, and the importance of protecting free speech and promoting a diverse marketplace of ideas. This article informs me of the ongoing content moderation and free speech argument. While I do understand the importance of impeding the spread of content that can be harmful and incite destructive behaviors, I still believe that content producers should still be able to express themselves and their sense of humor freely. \nThroughout the article, Keller emphasizes the issue's intricate nature and the trade-offs in regulating the reach of online content. He argues that any regulatory interventions should carefully balance the goals of promoting user safety, mitigating harmful effects, and preserving free expression; additionally, he calls for interdisciplinary collaboration and engagement between various stakeholders, including policymakers, platform operators, researchers, and Civil Society to develop nuanced and practical solutions. In the debate about how TikTok balances the need to moderate harmful content while respecting users' rights to freedom of expression, I argue that the algorithmic nature of TikTok's content distribution can inadvertently reinforce existing biases by amplifying certain voices, and in this case, the voices of students. Social media platforms such as TikTok can use transparency, accountability, and user empowerment to ensure that free expression is upheld while mitigating potential harm.\n The echo chamber positively represents a sense of community and support among students, providing a platform for sharing experiences, offering advice, and building connections with peers in similar educational contexts. While echo chambers can reinforce biases and limited perspectives, I found that \"Student TikTok\" did not include content that aligned with political or social viewpoints. I found the content to be very inclusive of all demographics as they discussed the shared experiences of a student in a learning environment. \nConclusion\nUnderstanding the function of algorithms is crucial in today's digital age for several reasons: informed decision-making and societal implications beyond individual user experiences. In summary, understanding the function of algorithms is essential to make informed decisions, protecting privacy, holding platforms accountable, and navigating the complex dynamics of digital platforms. It empowers individuals to actively engage with technology in a meaningful way, mitigate potential risk and promote a more transparent and user-centric digital ecosystem.\nWhile personalized social media algorithms can create filter bubbles and echo chambers where users are isolated from diverse perspectives, it enormously benefits users in various ways. Many users find their TikTok algorithms a safe community with like-minded individuals from underrepresented niches with voices that do not always reach mainstream media or more diverse algorithms. To reshape the dynamic between social media and users, we can encourage developing and implementing an algorithmic design that prioritizes diversity, equity, and inclusion. This involves considering algorithms' potential biases and impacts on marginalized groups and actively working to mitigate any adverse effects. This approach requires a proactive commitment to addressing biases, promoting fairness, and ongoing monitoring and adaptation as societal norms and understandings evolve.\nSocial media algorithms can significantly influence individuals' self-perception and identity construction through the influence of influencers. Social media platforms often provide a space where users showcase the highlights of their lives, emphasizing positive experiences, achievements, and happiness. Algorithms often create echo chambers by showing users content aligning with their beliefs and preferences. This can reinforce identities, values, or biases while limiting exposure to diverse perspectives and alternative viewpoints. Users may become more entrenched in their echo chambers, leading to a narrowing of their worldview and a reinforcement of their existing identity constructs. \nA stronger understanding of social media algorithms can result in a more informed and empowered society. Awareness of personalized content can encourage users to actively seek and engage with content outside of their filter bubbles promoting a balanced perspective. Secondly, with media literacy and further knowledge about social media algorithms, users can recognize when they are being presented with misinformation and evaluate the credibility of the content producer. Lastly, after studying the effects of social media algorithms, students and organizations can advocate and raise awareness of the potential consequences of echo chambers, polarization, and the dissemination of misinformation. \n\n\n\n\n\n\n\n\n\nReferences\nBakshy, E., Eckles, D., & Messing, S. (2015). Exposure to ideologically diverse news and opinion on Facebook. Science, 348(6239), 1130-1132. doi: 10.1126/science.aaa1160\nFelzmann, H., Fosch-Villaronga, E., Lutz, C., & Tamò-Larrieux, A. (2020). Towards transparency by design for artificial intelligence. Science and Engineering Ethics, 26(6), 3333-3361. doi: 10.1007/s11948-020-00276-4\nKarizat, N., Delmonaco, D., Eslami, M., & Andalibi, N. (2021). Algorithmic Folk Theories and Identity: How TikTok Users Co-Produce Knowledge of Identity and Engage in Algorithmic Resistance. Proceedings of the ACM on Human-Computer Interaction, 5(CSCW2), Article 305. https://doi.org/10.1145/3476046\nKeller, D. (2021). Amplification and its discontents: Why regulating the reach of online content is hard. Journal of Free Speech Law, 1, 227-268. Retrieved from https://www.journaloffreespeechlaw.org/keller.pdf\nKlonick, K. (2020). The Facebook Oversight Board: Creating an independent institution to adjudicate online free expression. Yale Law Journal, 129(2418). Retrieved from https://ssrn.com/abstract=3639234\nPariser, E. (2011). The Filter Bubble: What the Internet is Hiding from You. The Penguin Press.\nSwart, J. (2021). Experiencing algorithms: How young people understand, feel about, and engage with algorithmic news selection on social media. Social Media + Society, 7(2), 20563051211008828. doi: 10.1177/20563051211008828\nTufekci, Z. (2014). Engineering the public: Big data, surveillance and computational politics. First Monday, 19(7). Retrieved from https://firstmonday.org/ojs/index.php/fm/article/view/4901\nWilson, M. (2017). Algorithms (and the) everyday. Information, Communication & Society, 20(1), 137-150. doi: 10.1080/1369118X.2016.1149208"
  }
]